= Build a RAG chat agent

include::ROOT:partial$include.adoc[]

include::ROOT:partial$new-to-akka-start-here.adoc[]

This tutorial walks through building a Retrieval-Augmented Generation (RAG) chat agent. We start with a simple agent that streams responses from a large language model (LLM), and add retrieval functionality in separate parts of the tutorial. By the end, we will have an agent that uses the latest Akka documentation as its knowledge base, accessible through a web UI.

. xref:ask-akka-agent/the-agent.adoc[] — A streaming Agent that answers questions using an LLM and session memory.
. xref:ask-akka-agent/indexer.adoc[] — A Workflow that indexes local documentation into a vector database.
. xref:ask-akka-agent/rag.adoc[] — A helper class that performs RAG queries by combining vector search with the LLM.
. xref:ask-akka-agent/endpoints.adoc[] — Endpoints that expose a UI, support multiple sessions, and allow users to query the system.
